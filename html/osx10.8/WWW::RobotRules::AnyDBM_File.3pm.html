<!DOCTYPE html>
<html>
    <head>
        <meta name="description" content="This is a subclass of WWW::RobotRules that uses the AnyDBM_File package..." />
        <meta http-equiv="Content-Type" CONTENT="text/html; charset="utf-8" />
        <script type="text/javascript" src="../js/ga.js"></script>
        <title>WWW::RobotRules::AnyDBM_File - Persistent RobotRules</title>
        <META NAME="robots" CONTENT="all" />
    </head>
    
<content><pre>

WWW::RobotRules::AnyDBUserlContributed Perl DocWWW::RobotRules::AnyDBM_File(3)



NAME
       WWW::RobotRules::AnyDBM_File - Persistent RobotRules

SYNOPSIS
	require WWW::RobotRules::AnyDBM_File;
	require LWP::RobotUA;

	# Create a robot useragent that uses a diskcaching RobotRules
	my $rules = WWW::RobotRules::AnyDBM_File-&gtnew( 'my-robot/1.0', 'cachefile' );
	my $ua = WWW::RobotUA-&gtnew( 'my-robot/1.0', 'me@foo.com', $rules );

	# Then just use $ua as usual
	$res = $ua-&gtrequest($req);

DESCRIPTION
       This is a subclass of WWW::RobotRules that uses the AnyDBM_File package
       to implement persistent diskcaching of robots.txt and host visit
       information.

       The constructor (the new() method) takes an extra argument specifying
       the name of the DBM file to use.  If the DBM file already exists, then
       you can specify undef as agent name as the name can be obtained from
       the DBM database.

SEE ALSO
       WWW::RobotRules, LWP::RobotUA

AUTHORS
       Hakan Ardo &lthakan@munin.ub2.lu.se&gt, Gisle Aas &ltaas@sn.no&gt



perl v5.12.4			  2011-03-13   WWW::RobotRules::AnyDBM_File(3)
    </pre></body>

</html>
