<!DOCTYPE html>
<html>
    <head>
        <meta name="description" content="HTML::LinkExtor is an HTML parser that extracts links from an HTML..." />
        <meta http-equiv="Content-Type" CONTENT="text/html; charset="utf-8" />
        <script type="text/javascript" src="../js/ga.js"></script>
        <title>HTML::LinkExtor - Extract links from an HTML document</title>
        <META NAME="robots" CONTENT="all" />
    </head>
    
<content><pre>

HTML::LinkExtor(3)    User Contributed Perl Documentation   HTML::LinkExtor(3)



NAME
       HTML::LinkExtor - Extract links from an HTML document

SYNOPSIS
	require HTML::LinkExtor;
	$p = HTML::LinkExtor-&gtnew(\&cb, "http://www.perl.org/");
	sub cb {
	    my($tag, %links) = @_;
	    print "$tag @{[%links]}\n";
	}
	$p-&gtparse_file("index.html");

DESCRIPTION
       HTML::LinkExtor is an HTML parser that extracts links from an HTML
       document.  The HTML::LinkExtor is a subclass of HTML::Parser. This
       means that the document should be given to the parser by calling the
       $p-&gtparse() or $p-&gtparse_file() methods.

       $p = HTML::LinkExtor-&gtnew
       $p = HTML::LinkExtor-&gtnew( $callback )
       $p = HTML::LinkExtor-&gtnew( $callback, $base )
	   The constructor takes two optional arguments. The first is a
	   reference to a callback routine. It will be called as links are
	   found. If a callback is not provided, then links are just
	   accumulated internally and can be retrieved by calling the
	   $p-&gtlinks() method.

	   The $base argument is an optional base URL used to absolutize all
	   URLs found.	You need to have the URI module installed if you
	   provide $base.

	   The callback is called with the lowercase tag name as first
	   argument, and then all link attributes as separate key/value pairs.
	   All non-link attributes are removed.

       $p-&gtlinks
	   Returns a list of all links found in the document.  The returned
	   values will be anonymous arrays with the following elements:

	     [$tag, $attr =&gt $url1, $attr2 =&gt $url2,...]

	   The $p-&gtlinks method will also truncate the internal link list.
	   This means that if the method is called twice without any parsing
	   between them the second call will return an empty list.

	   Also note that $p-&gtlinks will always be empty if a callback routine
	   was provided when the HTML::LinkExtor was created.

EXAMPLE
       This is an example showing how you can extract links from a document
       received using LWP:

	 use LWP::UserAgent;
	 use HTML::LinkExtor;
	 use URI::URL;

	 $url = "http://www.perl.org/";  # for instance
	 $ua = LWP::UserAgent-&gtnew;

	 # Set up a callback that collect image links
	 my @imgs = ();
	 sub callback {
	    my($tag, %attr) = @_;
	    return if $tag ne 'img';  # we only look closer at &ltimg ...&gt
	    push(@imgs, values %attr);
	 }

	 # Make the parser.  Unfortunately, we don't know the base yet
	 # (it might be different from $url)
	 $p = HTML::LinkExtor-&gtnew(\&callback);

	 # Request document and parse it as it arrives
	 $res = $ua-&gtrequest(HTTP::Request-&gtnew(GET =&gt $url),
			     sub {$p-&gtparse($_[0])});

	 # Expand all image URLs to absolute ones
	 my $base = $res-&gtbase;
	 @imgs = map { $_ = url($_, $base)-&gtabs; } @imgs;

	 # Print them out
	 print join("\n", @imgs), "\n";

SEE ALSO
       HTML::Parser, HTML::Tagset, LWP, URI::URL

COPYRIGHT
       Copyright 1996-2001 Gisle Aas.

       This library is free software; you can redistribute it and/or modify it
       under the same terms as Perl itself.



perl v5.12.4			  2011-10-15		    HTML::LinkExtor(3)
    </pre></body>

</html>
